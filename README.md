## Product LED Growth Funnel Analysis- SaaS User Journey & Experimentation

**Overview**
---
**Users Analyzed:** 10,000 active users tracked across 8-week cohorts

**Events Tracked:** 51,000+ events capturing user behavior across funnel

**Key Finding:** 50% feature adoption bottleneck = $529K annual revenue leakage

**Solution Validated:** +87% Tooltip Guide test (p<0.001) generates $165.6K annually

**Market Expansion:** +47% Freemium model expands TAM to 556 customers = $318.6K opportunity

**Revenue Opportunity:** Combined interventions transform $680K baseline â†’ $1.25M (87% growth) over 7-week rollout

**Data Confidence:** <1% weekly cohort variance across 8 weeks = 99.9% production confidence

---

## Dashboard Pages##

**Page 1: Funnel Conversion Analysis**
Activation Flow: 10,000 â†’ 7,030 (70.3% activation in 1.1 days)

Feature Adoption: 3,515 users (50% bottleneck - critical insight)

Active Users: 1,237 weekly active users (12.4% of cohort)

PQL Stage: 378 product-qualified leads (3.8% of original)

Paid Conversion: 100 customers (26.4% PQL-to-Paid closing rate)

Waterfall Visualization: Shows exact drop-off points and optimization opportunities

**Page 2: Experiments & Retention**
A/B Test Results:

âœ… Tooltip Guide: +87% lift ($165.6K/yr) at p<0.001

âœ… Freemium Model: +47% lift ($318.6K/yr, 556 new customers)

âœ… Quick Start Onboarding: +31% lift ($204K/yr, minimal engineering)

Weekly Cohort Retention: 8-week progression showing user lifecycle

Statistical Rigor: All tests validated with <1% variance, 99.9% confidence

**Page 3: Revenue & Business Impact**
Revenue Baseline: $680K current annual revenue

Projected Revenue: $1.25M with all three interventions

Revenue Lift: $570K additional opportunity (87% growth)

Deployment Timeline: 7-week phased rollout (20% â†’ 50% â†’ 100%)

Payback Period: 2-4 weeks depending on implementation

---

Product--LED-Growth-Analysis/
â”œâ”€â”€ README.md (this file)
â”œâ”€â”€ LICENSE (MIT)
â”œâ”€â”€ Database_Setup.sql â† Schema for user, event, and test data
â”œâ”€â”€ Queries.sql â† Complex SQL for funnel, cohort, A/B analysis
â”‚
â”œâ”€â”€ ðŸ“Š PLG_Funnel_Analysis_Dashboard.pbix â† Main Power BI file
â”‚
â”œâ”€â”€ ðŸ PLG_Analytics_EDA_v2.py â† Python data generation & analysis
â”‚
â”œâ”€â”€ ðŸ“‹ PLG_Analytics_Report.pdf â† Executive summary with findings
â”‚
â”œâ”€â”€ ðŸ“„ PLG - MySQL Queries.pdf â† All SQL queries documented
â”‚
â””â”€â”€ ðŸ“š Documentation/
    â””â”€â”€ [Additional guides if needed]



 Executive Summary
 ---
This project demonstrates a complete, production-grade analytics pipeline that transforms raw user data into actionable business intelligence. Starting from a normalized MySQL database with 10,000 users and 51,000+ events, the analysis identifies a critical feature adoption bottleneck and quantifies a $570K/year revenue opportunity through A/B testing and statistical validation.

 Key Deliverables
 ---

ðŸ“Š EDA Report: PLG_Analytics_Report.pdf - Comprehensive exploratory data analysis with statistical findings

ðŸ“‹ SQL Queries: PLG_MySQL_Queries.pdf - 10 production-ready queries covering funnel, cohort, and revenue analysis

ðŸ“ˆ Power BI Dashboard: 3-page interactive dashboard with automated insights and recommendations

ðŸ Python Analysis: End-to-end data pipeline with chi-square testing and scenario modeling




ðŸ” Business Problem
---
Product-led growth platforms struggle with understanding user progression through the funnel and identifying where interventions create the most impact. This project addresses three critical questions:

Where do users drop off? Analysis reveals 50% activation-to-feature adoption drop-off, indicating a severe engagement issue that costs the company ~$200K annually in potential revenue.

Which interventions work best? Three A/B tests were designed to address different funnel stages: onboarding flow (+31% lift), pricing strategy (+47% lift), and feature adoption (+87% lift), all achieving statistical significance.

Is deployment safe? Weekly cohort analysis confirms metrics are stable (variance < 1%), validating that observed improvements are genuine and not noise.

<img width="1139" height="691" alt="Image" src="https://github.com/user-attachments/assets/a2bd9c2b-3c1a-4aee-8a69-4fb2bf275eeb" />



#  DASHBOARD Overview 


 **Funnel Conversion Analysis:**
 
Shows 10K users â†’ 7K activated (70%) â†’ 3.5K feature adoption (50% DROP-OFF) â†’ 378 paid (3.8% conversion)

Key Finding: Feature adoption is the bottleneck. Half of activated users never discover key features.

---

 **Experiments & Retention:** 

Tooltip Guide: +87% lift âœ… Deploy (solves feature adoption gap)

Freemium Model: +47% lift âœ… Deploy (highest revenue impact)

Quick Start: +31% lift âœ… Deploy (improves onboarding)

Validation: 99.8% cohort stability means these improvements will stick.

<img width="1150" height="689" alt="Image" src="https://github.com/user-attachments/assets/9a4f1ce5-67a9-4d16-bbc7-456d2bbc3e2d" />

---



Insights Identified
---

50% Feature Adoption Bottleneck Worth $200K+:
Half of activated users never use features, representing your largest revenue leakage opportunity.

+87% Lift Solution Validated (p < 0.001):
Tooltip guide test proves high-impact fix with 99.9% confidence, generating +$165.6K annually from simple UI change.

$570K Combined Revenue Opportunity (87% Growth):
Three interventions (tooltip, freemium, retargeting) transform revenue from $680K to $1.25M over 7 weeks.

<1% Cohort Variance Confirms Safe Deployment: 
User behavior is stable across 8 weeks, validating A/B results are genuine and safe to deploy at scale.

Mobile 26% Better Than Desktop, Direct 27% Better Than Paid: 
Segment gaps reveal optimization opportunities in device UX and paid targeting without major product changes.

<img width="1142" height="690" alt="Image" src="https://github.com/user-attachments/assets/22caf00b-0c32-4b5d-b6ca-3b303a9451a7" />


Methodology
---

# Phase 1: Data Generation & Infrastructure

The project begins with a 3NF normalized MySQL database designed to handle millions of records with proper relationships and constraints. Using Python and the Faker library, 10,000 realistic user profiles were generated across Organic, Paid, Referral, and Direct segments with device and platform distribution. Events were created to simulate realistic user journeys (51,231 total events) with probabilistic conversion rates at each funnel stage (signupâ†’activation: 70%, activationâ†’feature: 50%, featureâ†’PQL: 40%, PQLâ†’paid: 25%).

# Phase 2: Exploratory Data Analysis

Pandas-based EDA examined user demographics, funnel progression, and temporal patterns. Each user segment was analyzed separately to identify performance differences (Direct segment showed 4.3% conversion vs 3.4% for Paid). Time-to-value metrics were calculated (1.1 days signupâ†’activation, 11 days activationâ†’PQL, 15 days PQLâ†’paid), revealing that the activation bottleneck happens early when engagement barriers are highest.

# Phase 3: A/B Testing & Statistical Validation

Three concurrent tests were conducted on balanced samples (n=4,000 per variant). Chi-square tests confirmed statistical significance for all treatments (p < 0.001, 99.9% confidence level). The Feature Adoption test achieved the highest lift (+87%) using an in-app tooltip, demonstrating that simple, contextual guidance directly addresses the engagement gap identified in Phase 2.

# Phase 4: Power BI Visualization & Insights

A professional 3-page dashboard was built in Power BI to present findings: funnel visualization with drop-off indicators, A/B test comparison charts, and weekly cohort retention tracking. An insights bookmark synthesizes all analysis into 8 actionable boxes covering health assessment, statistical significance, revenue scenarios, and priority recommendations, making the findings accessible to both technical and non-technical stakeholders.

# Phase 5: Business Impact Modeling & Documentation

Three revenue scenarios were modeled based on test results: deploying the tooltip guide (low effort, +$165.6K/year), implementing freemium pricing (+$318.6K/year), or both (+$570K/year). Documentation ensures every number is traceable to its underlying calculation, supporting stakeholder confidence in deployment decisions.

Results 
--
## Funnel Performance Analysis

The complete funnel shows healthy top-of-funnel (70% activation, industry average) but severe mid-funnel friction. Feature adoption sits at just 35% of signups (vs. expected 50%+), representing the primary bottleneck. This 50% activation-to-feature drop-off translates directly to revenue loss: if adoption improved to 60%, an additional $165K would be generated annually based on current cohort data.

<img width="739" height="305" alt="Image" src="https://github.com/user-attachments/assets/615c8e32-6e89-4fe2-ba61-f21cf741f3c8" />


A/B Test Results with Statistical Validation
--

All three treatments showed statistically significant improvements. The Feature Adoption test using an in-app tooltip guide emerged as the clear winner: 28% conversion vs. 15% control, a +87% relative lift. This is particularly powerful because tooltip implementation requires minimal engineering effort (UI change only) and delivers the highest business impact.

<img width="734" height="327" alt="Image" src="https://github.com/user-attachments/assets/e0bc6a42-afe3-4ca8-8d11-b4133804781d" />


Cohort Stability & Risk Assessment
-
Weekly cohorts from August through November show consistent metrics (Â±0.09% activation variance, Â±0.15% feature adoption variance), confirming that conversion patterns are stable and not driven by seasonal or temporal anomalies. This low variance validates deployment safety: improvements observed in A/B tests reflect genuine behavioral changes, not noise.

Device & Segment Performance Insights
-
Mobile users outperform desktop (4.14% vs 3.28% conversion), while Direct acquisition channels show 27% higher conversion than Paid channels (4.32% vs 3.42%). These insights suggest prioritizing mobile experience optimization and investigating why Paid channels underperform relative to organic acquisition.


MAJOR RECOMMENDATIONS
-
Deploy Tooltip Guide First (2 Weeks, +$165.6K ROI):
Launch feature adoption tooltip immediately as quickest win with highest lift (+87%) and lowest effort (UI change only) to establish momentum.

Implement Freemium Pricing Second (4 Weeks, +$318.6K ROI):
Roll out freemium model in parallel to capture price-sensitive segment and expand customer base while tooltip impact is validated in production.

Launch Retargeting Campaign for Inactive Users (1 Week, +$45K ROI): 
Target 3,661 activated users who skip features with email/push using tooltip insights to capture low-hanging fruit while major initiatives deploy.

Monitor Feature Adoption Rate Weekly (Target: 49.7% â†’ 65%):
Track progress toward 65% feature adoption goal post-deployment with real-time dashboards to ensure improvements match A/B test results in production.

Phased 20% Rollout Before Full Deployment (Risk Mitigation): 
Test all interventions on 20% user segment first to validate production results before 100% deployment, protecting against unexpected environment-specific issues.
